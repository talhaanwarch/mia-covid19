{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "resized data.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPPpk3JdXSQx2GNfD86TthG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/talhaanwarch/mia-covid19/blob/main/resized_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcvlecBwfVG-",
        "outputId": "509032ae-58bc-4c38-8f56-61d7838eda1a"
      },
      "source": [
        "!nvidia-smi -L"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-f81d4715-9bb8-ffe5-01e5-80185e7015bf)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RYCrx53mdfOV",
        "outputId": "f95a3cfe-3a40-4bd1-c804-50881d27121c"
      },
      "source": [
        "#connect drive with colab notebook/\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSJFX50WeAuA"
      },
      "source": [
        "!cp /content/drive/MyDrive/covid/train.zip /content/\n",
        "!cp /content/drive/MyDrive/covid/val.zip /content/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHOYdivIgOuo"
      },
      "source": [
        "%%capture \n",
        "!unzip /content/train.zip\n",
        "!rm /content/train.zip\n",
        "!mv /content/resized /content/train\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INRl2NyagnOd"
      },
      "source": [
        "%%capture \n",
        "!unzip /content/val.zip -d val\n",
        "!rm /content/val.zip\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WQZnjjHeUD0"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "import cv2\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vaPmBTzetmj"
      },
      "source": [
        "# #load data, data loaded is in format of list of list containing folder and image paths\n",
        "# train_pos_path=[glob(folder+'*.jpg') for folder in glob('train/covid/*/')]\n",
        "# train_neg_path=[glob(folder+'*.jpg') for folder in glob('train/non-covid/*/')]\n",
        "# len(train_pos_path),len(train_neg_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hnrJiX2xe1oD"
      },
      "source": [
        "# #create labels for list of list images\n",
        "# train_pos_label=[[0]*len(i)  for i in train_pos_path]\n",
        "# train_neg_label=[[1]*len(i)  for i in train_neg_path]\n",
        "# len(train_pos_label),len(train_neg_label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0lfrq4we1q0"
      },
      "source": [
        "# #combine data\n",
        "# train_path=train_pos_path+train_neg_path\n",
        "# train_label=train_pos_label+train_neg_label\n",
        "# len(train_path),len(train_label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "InFE1HS_e1tZ"
      },
      "source": [
        "# #plit data \n",
        "# from sklearn.model_selection import train_test_split\n",
        "# train_path,val_path,train_label,val_label=train_test_split(train_path,train_label,test_size=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dThoXTzye1wb"
      },
      "source": [
        "# #flatten list\n",
        "# train_path = [item for sublist in train_path for item in sublist]\n",
        "# val_path = [item for sublist in val_path for item in sublist]\n",
        "# train_label = [item for sublist in train_label for item in sublist]\n",
        "# val_label = [item for sublist in val_label for item in sublist]\n",
        "# len(train_path),len(train_label),len(val_path),len(val_label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93AMfV08e1zM"
      },
      "source": [
        "# train_df=pd.DataFrame(zip(train_path,train_label),columns=['img','label'])\n",
        "# train_df = train_df.sample(frac=1).reset_index(drop=True)\n",
        "# train_df.to_csv('train_df.csv',index=False)\n",
        "# train_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qa-9mmr4e11s"
      },
      "source": [
        "# val_df=pd.DataFrame(zip(val_path,val_label),columns=['img','label'])\n",
        "# val_df = val_df.sample(frac=1).reset_index(drop=True)\n",
        "# val_df.to_csv('val_df.csv',index=False)\n",
        "# val_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSQSy5-Ee14V"
      },
      "source": [
        "# #calculate mean and standard deviation of random images\n",
        "# mean,std=[],[]\n",
        "# for i in train_df.img[0:100]:\n",
        "#     img=cv2.imread(i,0)/255.0\n",
        "#     mean.append(np.mean(img)),std.append(np.std(img))\n",
        "    \n",
        "# print('mean',np.mean(mean))\n",
        "# print('std',np.mean(std))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "ws-hYMlXe17T",
        "outputId": "677064de-4be9-4897-d7c9-0b00dba28dff"
      },
      "source": [
        "train_df=pd.read_csv('/content/drive/MyDrive/covid/train_df.csv')\n",
        "val_df=pd.read_csv('/content/drive/MyDrive/covid/val_df.csv')\n",
        "train_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>img</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>train/non-covid/ct_scan_790/80.jpg</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>train/non-covid/ct_scan_580/36.jpg</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>train/covid/ct_scan_11/122.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>train/non-covid/ct_scan_199/280.jpg</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>train/non-covid/ct_scan_530/234.jpg</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                   img  label\n",
              "0   train/non-covid/ct_scan_790/80.jpg      1\n",
              "1   train/non-covid/ct_scan_580/36.jpg      1\n",
              "2       train/covid/ct_scan_11/122.jpg      0\n",
              "3  train/non-covid/ct_scan_199/280.jpg      1\n",
              "4  train/non-covid/ct_scan_530/234.jpg      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Jo72jzHe8Ie"
      },
      "source": [
        "import torch \n",
        "from torchvision import transforms \n",
        "import torchvision.models as models\n",
        "import torch.nn as nn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-XwPy3le_Rr"
      },
      "source": [
        "aug=transforms.Compose([\n",
        "                        transforms.Resize((224,224)),\n",
        "                        transforms.Grayscale(),\n",
        "                        transforms.RandomHorizontalFlip(p=0.5),transforms.RandomVerticalFlip(p=0.5),\n",
        "                        transforms.RandomRotation(degrees=5),\n",
        "                        \n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.Normalize([0.4, ], [0.3,]),\n",
        "\n",
        "                        ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqwG1w1OfAZU"
      },
      "source": [
        "from PIL import Image\n",
        "class dfloader(torch.utils.data.Dataset):\n",
        "    \n",
        "    def __init__(self,img_id,img_label,transform=None):\n",
        "        self.img_id = img_id    \n",
        "        self.img_label=img_label\n",
        "        self.transform=transform\n",
        "        \n",
        "    def __getitem__(self,index):\n",
        "        if type(index) == torch.Tensor:\n",
        "          index = index.item()\n",
        "        img_ind=self.img_id[index]\n",
        "        label_ind=self.img_label[index]\n",
        "\n",
        "        img = Image.open(img_ind).convert('L')\n",
        "      \n",
        "        if self.transform:\n",
        "           img=self.transform(img) \n",
        "  \n",
        "        return img ,label_ind\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.img_id)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7WP2v9vfAb6"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "class Fire1(nn.Module):\n",
        "   \n",
        "    def __init__(self, in_channels, squeeze_channels,expand_channels):\n",
        "        super(Fire1, self).__init__()\n",
        "\n",
        "        # squeeze \n",
        "        self.squeeze = nn.Conv2d(in_channels, squeeze_channels, kernel_size=1)\n",
        "        self.relu = nn.LeakyReLU()\n",
        "\n",
        "        # expand\n",
        "        self.expand_1x1 =nn.Conv2d(squeeze_channels, expand_channels, kernel_size=1)\n",
        "        self.expand_3x3 =nn.Conv2d(squeeze_channels, expand_channels, kernel_size=3,padding=1)\n",
        "        \n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.squeeze(x)\n",
        "        x= self.relu(x)\n",
        "        x = torch.cat([self.expand_1x1(x),self.expand_3x3(x)], dim=1)\n",
        "        x = self.relu(x)\n",
        "        return x\n",
        "    \n",
        "    \n",
        "class MyModelV3(torch.nn.Module):\n",
        "    \n",
        "    def __init__(self):\n",
        "        super(MyModelV3, self).__init__()\n",
        "        self.net = torch.nn.Sequential(\n",
        "                 nn.Conv2d(in_channels=1,out_channels=32,kernel_size=3,stride=2),\n",
        "                 nn.MaxPool2d(kernel_size=3,stride=2),\n",
        "                 nn.LeakyReLU(),\n",
        "                 nn.BatchNorm2d(32),\n",
        "                 Fire1(in_channels=32, squeeze_channels=16,expand_channels=32),\n",
        "                 Fire1(in_channels=64, squeeze_channels=16,expand_channels=64),\n",
        "                 nn.MaxPool2d(kernel_size=3,stride=2),\n",
        "                 #nn.BatchNorm2d(128),\n",
        "                 Fire1(in_channels=128, squeeze_channels=32,expand_channels=96),\n",
        "                 Fire1(in_channels=192, squeeze_channels=32,expand_channels=128),\n",
        "                 nn.MaxPool2d(kernel_size=3,stride=2),\n",
        "                 #nn.BatchNorm2d(256),\n",
        "                 Fire1(256, 48, 160),\n",
        "                 Fire1(320, 48, 160),\n",
        "                 #nn.BatchNorm2d(320),\n",
        "                 nn.Conv2d(in_channels=320,out_channels=128*2,kernel_size=1,stride=2),\n",
        "                 nn.LeakyReLU(),\n",
        "                 nn.Conv2d(in_channels=128*2,out_channels=32,kernel_size=1,stride=1),\n",
        "                 nn.LeakyReLU(),\n",
        "                 nn.Conv2d(in_channels=32,out_channels=16,kernel_size=1,stride=1),\n",
        "                 nn.LeakyReLU(),#just for testing\n",
        "                 #nn.Conv2d(in_channels=32,out_channels=16,kernel_size=1,stride=1),\n",
        "                 nn.Flatten(),\n",
        "                 #PrintShape(),\n",
        "                 nn.Linear(784, 1),\n",
        "                 # nn.Linear(512*2, 512)\n",
        "                \n",
        "               \n",
        "                )        \n",
        "    def forward(self, x):\n",
        "        return self.net(x)    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bI-79-OifAef"
      },
      "source": [
        "from sklearn.metrics import classification_report,f1_score\n",
        "from time import time\n",
        "\n",
        "def get_accuracy(y_true, y_pred):\n",
        "    assert y_true.ndim == 1 and y_true.size() == y_pred.size()\n",
        "    y_pred = y_pred > 0.5\n",
        "    return (y_true == y_pred).sum().item() / y_true.size(0)\n",
        "\n",
        "def fit_train(loader):\n",
        "    loss_sum=0\n",
        "    acc_sum=0\n",
        "    scaler = torch.cuda.amp.GradScaler() \n",
        "    for batch in loader:\n",
        "        img,label=batch\n",
        "        with torch.cuda.amp.autocast(): \n",
        "          img,label = img.to(device),label.to(device)\n",
        "          out=model(img)\n",
        "          loss=criterion(out.view(-1),label.float())\n",
        "        opt.zero_grad()\n",
        "        scaler.scale(loss).backward()\n",
        "        #loss.backward()\n",
        "        scaler.step(opt)\n",
        "        #opt.step()\n",
        "        scaler.update()\n",
        "        loss_sum+=loss.item()\n",
        "        acc_sum += get_accuracy(label,out.view(-1))\n",
        "    return loss_sum,acc_sum\n",
        "def fit_val(loader):\n",
        "    loss_sum=0\n",
        "    acc_sum=0\n",
        "    for batch in loader:\n",
        "        img,label=batch\n",
        "        img,label = img.to(device),label.to(device)\n",
        "        out=model(img)\n",
        "        loss=criterion(out.view(-1),label.float())\n",
        "        loss_sum+=loss.item()\n",
        "        acc_sum += get_accuracy(label,out.view(-1))\n",
        "    return loss_sum,acc_sum\n",
        "\n",
        "def fit_test(loader):\n",
        "  test_pred=[]\n",
        "  for img,_ in loader:\n",
        "    test_pred.append(model(img.to(device)))\n",
        "  test_pred=torch.cat(test_pred,dim=0)\n",
        "  y_pred=test_pred.cpu().numpy()\n",
        "  return y_pred\n",
        "\n",
        "\n",
        "def fit(model,train_loader,val_loader,test_loader=None,epoch=10,scheduler_step=None,verbose=None):\n",
        "  \n",
        "  train_loss_plt=[]\n",
        "  val_loss_plt=[]\n",
        "  train_acc_plt=[]\n",
        "  val_acc_plt=[]\n",
        "  for ep in range(epoch):\n",
        "    start=time()\n",
        "    #start training loop\n",
        "    train_loss,train_acc=fit_train(train_loader)\n",
        "    #start validation loop\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        val_loss,val_acc=fit_val(val_loader)\n",
        "    end=np.round((time()-start)/60,2) #time in minute\n",
        "    model.train()\n",
        "\n",
        "    #calculate print and append the results for plotting purpose\n",
        "    val_avg_loss=np.round(val_loss/len(val_loader),2)#val loss of all batches of one epoch\n",
        "    train_avg_loss=np.round(train_loss/len(train_loader),2)# train loss of all batches of one epoch\n",
        "    train_avg_acc=np.round(train_acc/len(train_loader),2)#train acc of all batches of one epoch\n",
        "    val_avg_acc=np.round(val_acc/len(val_loader),2)#val acc of all batches of one epoch\n",
        "    if scheduler_step:\n",
        "      scheduler.step(val_avg_loss)\n",
        "    if verbose:\n",
        "      print('Epoch {}, time {} min , train acc  {}, train loss {} , val acc is {}, loss is {}, learning rate is {} '.format\n",
        "            (ep,end,train_avg_acc,train_avg_loss,val_avg_acc,val_avg_loss,opt.param_groups[0]['lr']))\n",
        "    train_loss_plt.append(train_avg_loss)  #append loss of training data  \n",
        "    val_loss_plt.append(val_avg_loss)     #append loss of validation data\n",
        "    train_acc_plt.append(train_avg_acc)  #append acc of training data  \n",
        "    val_acc_plt.append(val_avg_acc)     #append acc of validation data\n",
        " \n",
        " #test phase\n",
        "  if test_loader:\n",
        "      model.eval()\n",
        "      with torch.no_grad():\n",
        "         y_pred=fit_test(test_loader)\n",
        "  \n",
        "  return [train_loss_plt,val_loss_plt,train_acc_plt,val_acc_plt],[model,"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWdQno1kfAhb"
      },
      "source": [
        "from torch.utils.data.dataloader import DataLoader\n",
        "train=dfloader(train_df.img.values,train_df.label.values,transform=aug)\n",
        "val=dfloader(val_df.img.values,val_df.label.values,transform=aug)\n",
        "train_loader = DataLoader(train,shuffle=True,num_workers=0,batch_size=512)\n",
        "val_loader = DataLoader(val,shuffle=True,num_workers=0,batch_size=512)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PvzWi4q1fAjs"
      },
      "source": [
        "device=torch.device('cuda')\n",
        "model=MyModelV3().to(device)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "opt=torch.optim.AdamW(params=model.parameters(),lr=0.001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4N8YLePIfFRl",
        "outputId": "f624f62f-217c-40a7-a22f-2551ff3ea171"
      },
      "source": [
        "res,mod=fit(model,train_loader,val_loader,epoch=15,scheduler_step=False,verbose=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0, time 13.9 min , train acc  0.45, train loss 0.69 , val acc is 0.47, loss is 0.69, learning rate is 0.001 \n",
            "Epoch 1, time 14.42 min , train acc  0.6, train loss 0.62 , val acc is 0.68, loss is 0.59, learning rate is 0.001 \n",
            "Epoch 2, time 14.43 min , train acc  0.74, train loss 0.49 , val acc is 0.73, loss is 0.55, learning rate is 0.001 \n",
            "Epoch 3, time 14.47 min , train acc  0.82, train loss 0.37 , val acc is 0.75, loss is 0.59, learning rate is 0.001 \n",
            "Epoch 4, time 14.47 min , train acc  0.88, train loss 0.27 , val acc is 0.75, loss is 0.69, learning rate is 0.001 \n",
            "Epoch 5, time 14.35 min , train acc  0.92, train loss 0.19 , val acc is 0.76, loss is 0.82, learning rate is 0.001 \n",
            "Epoch 6, time 14.38 min , train acc  0.94, train loss 0.15 , val acc is 0.78, loss is 0.75, learning rate is 0.001 \n",
            "Epoch 7, time 14.42 min , train acc  0.95, train loss 0.12 , val acc is 0.78, loss is 0.75, learning rate is 0.001 \n",
            "Epoch 8, time 14.32 min , train acc  0.96, train loss 0.1 , val acc is 0.78, loss is 0.87, learning rate is 0.001 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AgIku0QBi4tR"
      },
      "source": [
        "state = {\n",
        "        'epoch': 15,\n",
        "        'state_dict': model.state_dict(),\n",
        "        'optimizer': opt.state_dict(),\n",
        "}\n",
        "savepath=/content/drive/MyDrive/covid/+'0to15.pt'\n",
        "torch.save(state,savepath)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZZJs-zn_Z7t"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}